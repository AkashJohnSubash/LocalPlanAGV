\chapter{Background}\label{chap:background}

This section outlines a selection of the mathematical fundamentals of the system theory and optimization fields applied in this thesis. 
\begin{figure}[h!tbp]
    \begin{center}
        \def\svgwidth{0.5\textwidth}
        \input{../figures/agv_dim.pdf_tex}
        \caption{Test AGV dimensions \cite{malitzky_markus_mechanical_nodate}.}
        \label{mpc_agv}
    \end{center}
\end{figure}

\par MPC is considered here due to its inherent ability to deal with nonlinear systems, while explicitly respecting constraints. This locally optimal control scheme for navigation, is intended as a follow-up to the ek robotics' inhouse state-of-art optimization-based local planner, implemented in the \ac{TEB}.

\section{System modelling} \label{back_modelling}
Since modelling can be classified under many criteria based on application, we henceforth refer only to analytic models as opposed to data-driven models \cite{frison_model_nodate}, with a particular focus on kinematic models relying on a state-space representation. 
\subsection{State-space models}
At its core, a state-space model represents a mathematical representation of a time-varying system by describing its behavior in terms of state variables, inputs, parameters, and outputs. Modelling a system of sufficient accuracy involves a careful selection of appropriate attributes, to numerically approximate real-world behaviour. In the realm of state-space control, a system's evolution over time is encapsulated in a set of differential equations, typically represented in matrix form. The state vector $\zeta$ $\in$ $\mathbb{R}$$\mathrm{^{n_{\zeta}}}$, encompassing all relevant system variables, serves as a concise and comprehensive description of the system's internal state at any given time. Meanwhile, the input vector $u$ $\in$ $\mathbb{R}$$\mathrm{^{n_{u}}}$ influences the system, driving it towards a desired state or response. The connection between the input, state, and output is encapsulated in a set of matrices, forming the state-space representation. The state-space representation not only captures the inherent dynamics of a system but also facilitates the incorporation of various control techniques, including state feedback, observer design, and optimal control.
The system evolution in the physical world represented by continuous time systems can be mathematically defined as a function of $\zeta(t)$ and $u(t)$. The resulting explicit \ac{ODE}s depicted below involves the transition function 
$f : (\mathbb{R}^{n_\zeta} \times \mathbb{R}^{n_u}) \to \mathbb{R}^{n_\zeta}$
\begin{equation}
    \dot{\zeta}(t) = f(\zeta(t),u(t),t) \label{sysODE}
\end{equation}

\par Among several other classifications, kinematic and dynamic models represent two distinct yet interconnected approaches to understanding the motion and behavior of systems, often applied in the realms of physics, engineering, and robotics. These models offer complementary insights into the intricate nature of movement, providing a comprehensive framework for analysis.

\par Kinematic models focus on describing the geometry of motion without delving into the forces and torques that drive the movement. In essence, kinematics is concerned with position, velocity, and acceleration, providing a fundamental understanding of how objects or systems move through space. The equations governing kinematic models articulate the relationship between these key attributes, allowing for the prediction of trajectories and the characterization of motion patterns.

\par On the other hand, dynamic models delve into the forces and torques that influence the motion of a system. Unlike kinematics, dynamics considers the causes behind the observed motion, incorporating principles of Newtonian mechanics or other relevant physical laws.

\par In many cases, both kinematic and dynamic models are employed in tandem to provide a more comprehensive analysis of complex systems. Kinematic information lays the foundation by outlining the basic patterns of motion, while dynamic models augment this understanding by revealing the underlying forces and interactions governing those motions. This integrated approach is particularly crucial in fields such as robotics, where precise control of motion is essential for efficient and accurate performance.

\par \ac{ODE}s play a central role in representing how these systems evolve, as each equation in the system corresponds to a specific degree of freedom or dimension, serving as the mathematical backbone for predicting trajectories and understanding the spatial configuration of objects or systems as they traverse through time.
Solving the \ac{ODE} (\ref{sysODE}) on the boundary, where the state constrained as $\zeta(0)$ = $\zeta_{0}$ and with a particular control trajectory leads to the definition of an \ac{IVP}.
\begin{align}
    \dot{\zeta}(t) &= f(\zeta(t), u(t), t), &  ~  \zeta(t_{0}) = \zeta_{0}, &  ~  t \in [t_{0}, t_{end}]\label{IVP}
\end{align}
\par Given differentiability with respect to $\zeta$, this \ac{IVP} has a unique solution \cite{gros_numerical_2022}, which also serves as motivation for the subsequent Section \ref{IdxRed} outlining the \ac{DAE} index reduction.


\section{Numerical optimal control}\label{back_opt_control}
Aiming to deploy \ac{MPC}, we discuss its foundation of mathematical optimization, \ac{OCP}s, and discrete-time simulation methods. Providing only a brief glimpse into these vastly researched disciplines, we encourage the reader to refer to \cite[Subject Index C]{rawlings_james_model_2020} for a more detailed exposition.

\subsection{Numerical simulation and optimization}
Forward simulation of the state-space model being a cornerstone of \ac{MPC}, relies on computationally cheap and accurate numerical integration methods \cite[p. 7]{gros_numerical_2022}. Since discretization of the state and control trajectory is often the sole option for the computational feasibility of the control scheme, we proceed by assuming the control inputs are piecewise constants between the consecutive samples of the system. This approach known as Zero Order Hold \cite{gros_numerical_2022}, parameterizes the controls as below
\begin{align}
    u(t) &= u_{k}, \qquad u_{k} \in \mathbb{R}^{n_u},&~\forall t \in [t_{k}, t_{k+1}].\label{ZeroOrder}
\end{align}
Selecting a uniform time grid of length $N$ over the time interval $[t_{0}, t_{N}]$ to discretize the state, we obtain
\begin{align}
    T_s &= \dfrac{t_{N}-t_0}{N}, & ~ N \in \mathbb{I}^+\\
    t_k &= t_0 + kT_s, &  ~ k = 0, 1, ..., N.
\end{align}
\par Using numerical integration schemes for forward simulation, we obtain the discretized state $\zeta_{k}$ defined as $\zeta(t_{k})$ at the sampling instants $t_{k}$ for $k$ = $0, 1, ..., N$ 

\par The most straightforward of the first-order explicit schemes, known as the Euler method computes the solution map of the \ac{IVP} in Equation (\ref{IVP}) recursively as illustrated below, with $\zeta_{0} \coloneq \bar{\zeta_{0}}$
\begin{align}
\zeta_{k+1} &= \zeta_{k} + T_{s} f(\zeta_{k}, u_{k}), &  ~  k =  0, 1, ..., N - 1.
\end{align}
\par For very small time intervals $T_s$, this integration scheme is stable with bounded errors \cite[p. 12]{gros_numerical_2022}, and by subdividing the interval $T_s$ further 
into smaller steps, the accuracy of the solution map is increased. The price, however, is the linear increase in the number of function evaluations of $f$ in Equation (\ref{IVP}) with the increased accuracy. This leads to the investigation of computationally cheaper methods. 

\par The \ac{RK} method of fourth order (\ac{RK}4) \cite[p. 168]{gros_numerical_2022} is a fairly popular method in this regard. With the help of intermediate stages as defined below, \ac{RK}4 achieves an accuracy in the solution map comparable to the Euler method with much less computational effort, as it can afford larger step sizes than the latter. 
Starting with $\zeta_{0} \coloneq \bar{\zeta}_0$, the forward simulation is computed as
\begin{subequations}
\begin{align}
    m_1 &= f(\zeta_{k}, u_k)\\
    m_2 & = f(\zeta_{k} + \frac{h}{2} m_1, u_k)\\
    m_3 & = f(\zeta_{k} + \frac{h}{2} m_2, u_k)\\
    m_4 & = f(\zeta_{k} + h\,m_3, u_k)\\
    \zeta_{k+1} &= \zeta_{k} + \dfrac{h}{6}(m_1 + 2\,m_2 + 2\,m_3 + m_4).
\end{align}
\end{subequations}
\par Additionally for models with fast and slow dynamics, which we refer to as stiff systems, implicit integration schemes better handle instability arising from numerical integration inaccuracies. Instead of the aforementioned explicit integration scheme which demands very short step sizes to accurately capture the fast dynamics, we use the implicit \ac{RK}4 scheme as defined in  \cite[p. 172]{gros_numerical_2022}.

\par Since each of these resulting equations involves implicit function evaluations, we no longer retain the lower triangular matrix while solving them as in the explicit schemes, leading to higher computational time complexity.

\begin{figure}[htbp]
	\begin{center}
        \def\svgwidth{0.9\textwidth}
        \input{../figures/ocp.pdf_tex}
        \caption{Principle of predictive control}
        \label{fig_ocp}
	\end{center}
\end{figure}

\subsection{Optimal Control Problem and Nonlinear Programming}
\par Optimal control problems are essentially dynamic programming \cite[Ch. 8]{gros_numerical_2022}, \cite[p. 89]{rawlings_james_model_2020} problems over a time horizon to determine control and state trajectories that minimize an objective
function, as illustrated in Figure \ref{fig_ocp}. The \ac{NLP} \cite[p. 38]{gros_numerical_2022} are a special class of continuous optimization problems that are employed to approximately solve such \ac{OCP}s, and we state a simple \ac{NLP} below.

\begin{mini!}
	{\substack{w \in \mathbb{R}^{n_w}}}{J(w)\,}
	{}{}
	\addConstraint{}{g(w)}{=0}
	\addConstraint{}{h(w)}{\leq0}
\end{mini!}
An objective function$(J(w))$ determines the optimality of a solution candidate $w$, and constraint functions $(g(w),\,h(w))$ are vectors of equality and inequality constraints respectively that determine the feasibility of that solution candidate \cite{gros_numerical_2022}.

With system dynamics defined in the continuous time domain, denoted by $\zeta(\cdot)$ and  $u(\cdot)$ respectively, we observe that we have at hand an infinite-dimensional optimization problem. Structuring the \ac{OCP} as commonly found in literature \cite[p. 161]{gros_numerical_2022}, \cite[p. 499]{rawlings_james_model_2020}, we obtain
\begin{mini!}
	{\zeta(\cdot),u(\cdot)}{E(\zeta(T)) + \int_{0}^{T} \! L(t,\zeta(t),u(t)) \, dt \label{eq:ocp_obj} }
	{\label{eq:ocp}}{}
	\addConstraint{}{\zeta(0)-\bar{\zeta}_0}{=0}
	\addConstraint{}{f(t,\zeta(t),\dot{\zeta}(t), u(t))}{=0,}{\quad \forall t \in [0, T]} \label{EqContinue}
	\addConstraint{}{g(t,\zeta(t), u(t))}{=0,}{\quad \forall t \in [0, T]}\label{eq:ocp_eq}
	\addConstraint{}{h(t,\zeta(t),u(t))}{\leq 0,}{\quad \forall t \in [0, T]} \label{eq:ocp_ineq}
    \addConstraint{}{r(\zeta(T))}{\leq 0.}
\end{mini!}
To solve such a continuous time \ac{OCP}, we discretize the continuous time \ac{OCP} alluding to the class of $direct\,methods$. This resulting finite-dimensional optimization problem is subsequently solved with numerical optimization algorithms \cite[p. 500]{rawlings_james_model_2020}.

\subsection{Direct Multiple Shooting}\label{subsec:direct_multiple_shooting}
In this direct method, the optimization routine solves 
simultaneously the simulation and the optimization problem, considering the discretized state and controls over the entire horizon as optimization variables. The integral objective function from the continuous \ac{OCP} 
and the path constraints are also approximated numerically on each interval. A finite-dimensional optimization problem defined and solved with the Direct Multiple Shooting method is stated as
\begin{mini!}
	{u_{0}, \zeta_{0}, ...,u_{N-1}, \zeta_{N}}{E(\zeta_{N}) + \sum_{k=0}^{N-1} \! L(\zeta_k,u_k)}
	{\label{eq:disc_ocp_form}}{}
	\addConstraint{}{\zeta_0 -\bar{\zeta}_0 }{=0}
	\addConstraint{}{\zeta_{k+1} - \phi(\zeta_{k}, u_{k})}{=0,}{\qquad k = 0,\ldots,N-1}
	\addConstraint{}{g(\zeta_{k}, u_{k})}{=0,}{\qquad k = 0,\ldots,N-1}
	\addConstraint{}{h(\zeta_{k},u_{k})}{\leq 0,}{\qquad k = 0,\ldots,N-1}
    \addConstraint{}{r(\zeta_{N})}{\leq 0.}
\end{mini!}

\par A special sub-class of \ac{NLP}s with affine constraints, including system dynamics and a linear quadratic objective function, Quadratic Programs(QP), that are particularly relevant to us for use as \ac{SQP}-subproblems in the software framework of acados \cite[p. 40]{gros_numerical_2022}.

\subsection{Model Predictive Control}

Using the previously described framework of optimization for system control in conjunction with the discretized model, we prepare to deploy the control scheme with measurement feedback over a long time horizon, to compensate for the unmodelled perturbations intrinsic to physical systems. Applying the control from the approximate solution of the \ac{OCP} from Equation (\ref{eq:ocp}) iteratively using the real-time iteration (RTI) scheme \cite{gros_linear_2020}, the predicted and observed \ac{AGV} states are bound to diverge without feedback. The intuitive argument for this disparity is that low-fidelity models can not handle noise-prone processes inherent in mechanical systems over long time spans in open-loop \cite[Ch. 15]{gros_numerical_2022}.

\par A suitable approach to address this challenge is acquiring the current state of the plant and recomputing the optimal feedback control at each timestep online, thereby closing the loop. This equips the controller to better handle the model-plant-mismatch, by effectively limiting its error propagation. However, since not all states are measurable, some of them must instead be estimated with a sufficiently accurate observer. Thus, closed-loop control boils down to solving the \ac{OCP} described in Equation (\ref{eq:ocp}) iteratively with updated initial conditions.

\par Finally, embedded deployment of the control scheme often calls for trading off computation time against solver accuracy, which motivates short prediction horizons, conservative sampling durations, and numerical approximations. For the solver to meet the computational deadlines, we reformulate the \ac{NLP} as a QP, using the matrix structure exploiting solver and integration schemes provided by acados \cite{gros_linear_2020}.
\par In essence, we forecast with an analytical model for our \ac{OCP}, solve the open-loop control problem approximately, and repeat the entire process with the new estimate of the initial value \cite[p. 283]{gros_numerical_2022}.
\section{Related Work}\label{back_related}
Trajectory tracking for automotive applications with well-defined lanes has been vastly researched in the recent past in the interest of autonomous driving. In this Chapter, we summarize some of the available literature that influenced this work, which involves modelling the dynamics, the track and obstacles appropriately to achieve real-time deployment of the control scheme on the test \ac{AGV}. Apart from introducing the tricycle kinematic model in the Cartesian frame, Ljubi et al. \cite{ljubi_path_2023} introduces path-planning algorithms based on heuristic approaches. The fundamentals for lane-bounded time optimal control established using a single track model in the Frenet frame with \ac{SQP} algorithms demonstrated in the work of Verschueren et al. \cite{verschueren_towards_2014}, is improved upon in  \cite{kloeser_nmpc_2020} by Klöser et al. Here, the lateral acceleration is modelled explicitly with a progress maximization objective reformulation relevant to racing, and road boundary deflection. Improved parametrization of reference tracks to avoid singularities in the Frenet-Cartesian transforms is subsequently presented in detail by Reiter et al. in \cite{reiter_parameterization_2021}.

\par An optimization-based planning scheme with obstacle evasion known as the \ac{TEB} by Rosmann et al. \cite{rosmann_efficient_2013} made popular with an open source implementation in \ac{ROS}, demonstrated the feasibility of compute-intensive planners at ek robotics in mobile robots for a hospital environment. This laid the groundwork for investigating the deployment of more rigorous collision avoidance techniques. \ac{TEB} uses a multi-objective optimization framework to penalize vehicle dynamics, kinematics, and trajectory tracking. By formulating the navigation problem as an elastic band attracted to way-points and repelled by obstacles with an approximate kinematic model, these objectives
are pitted against each other ensuring arduous tuning for solver convergence. MPC however, imposes hard constraints on kinematics and dynamics, providing stronger guarantees of meeting the continuity conditions (26c). This can be inferred from the fact that the solver-generated multiplier vectors satisfy the KKT conditions [25, p. 38], which are the first-order necessary conditions of candidate minima. The \ac{TEB} is further extended to maintaining multiple candidate topologies with an approximated kinematic model for car-like vehicles in \cite{rosmann_integrated_2017}. A potential field method, modelling objective terms representing repulsive fields promoting evasive manoeuvres is introduced by Jiang et al. in \cite{jiang_obstacle_2016} for autonomous road vehicles. Subsequently, the burden of tuning such methods compared to geometric obstacle constraints is discussed by Xing et al. in \cite{xing_vehicle_2022}. Strict collision avoidance assurance, promising safety in human-machine interaction unlike in the previous approaches, can be better realized when formulated with hard constraints such as ellipses by Brito et al. in \cite{brito_model_2020}, multiple circles by Galiev et al. in \cite{galiev_optimization_2019}, or hyperplanes by Brossette et al. in \cite{brossette_collision_2017}. The single-track bicycle model tested on miniature race cars at the University of Freiburg is further extended in simulation exploring multiple \ac{ODE} formulations in the Cartesian and Frenet frames by Reiter et al. in \cite{reiter_frenet-cartesian_2023} motivated by retaining convex constraint specification for circular and elliptical objects while using the implicit curvilinear states of the Frenet frame. Employing the native DAE formulation stemming from this joint state representation by Xing et al. in \cite{xing_vehicle_2022} uses linear MPC for trajectory tracking. For a more realistic environment representation, an approach introducing non-circular convex polygonal obstacles for unmanned aerial vehicles by Zhang et al. in \cite{zhang_enlarged_2023} elaborates on geometric approximations for quadratic programming instead of Mixed Integer Programming (MIP).
\par Motivated by this plethora of existing research, we aim to design a real-time feasible NMPC scheme for an \ac{AGV} at ek robotics, validated in simulation and on the test vehicle using acados. We further provide some insights into real-time behaviour aboard the test setup, with quantifiable performance metrics.

\par One of the main contributions of this work is the experimental validation of the proposed optimal controllers on an \ac{AGV}. To this end, we adapt the known progress maximization formulation for the single-track model in the Frenet coordinate frame, to the tricycle kinematic system. Subsequently, we outline the index reduction for the resulting dual formulation, showing that it also holds for this scenario.
